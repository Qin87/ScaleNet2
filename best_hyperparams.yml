# 76.71 ± 1.92
squirrel:
  lr: 0.01
  hidden_dim: 128
  layer: 4
  jk: "max"
  patience: 400
#  conv_type: "complex-fabernet"
  alpha: 1
  normalize: True
  k_plus: 5
  exponent: -0.25
#  weight_penalty: exp
  num_runs: 10  # original split

# 80.33 ± 1.19
chameleon:   # run comment out redundancy :  0.7953947424888611 +- 0.012484612170673247  0.7953947424888611 +- 0.0124846121706
  lr: 0.005
  hidden_dim: 128
  layer: 5
  jk: "cat"
  patience: 400
  conv_type: "fabernet"
  alpha: 1
  normalize: True
  k_plus: 4
  exponent: -0.25
  weight_penalty: exp
  num_runs: 10  # original split

# 64.43 ± 0.28
arxiv-year:
  lr: 0.005
  hidden_dim: 256
  layer: 6
  jk: "cat"
  patience: 200
  conv_type: "fabernet"
  weight_decay: 0.1
  k_plus: 1
  exponent: -0.25
  lrelu_slope: 0
#  weight_penalty: exp
  num_runs: 5  # original split

# 75.10 ± 0.03
snap-patents:
  lr: 0.01
  hidden_dim: 32
  layer: 5
  jk: "max"
  patience: 400
  normalize: True
  conv_type: "fabernet"
  alpha: 0.5
  weight_decay: 0.1
  k_plus: 2 
  exponent: -0.25
#  weight_penalty: exp
  lrelu_slope:  0
  num_runs: 5  # original split

# 92.24 ± 0.432
directed-roman-empire:
  lr: 0.01
  hidden_dim: 256
  layer: 5
  jk: "cat"
  dropout: 0.2
  patience: 200
  conv_type: "fabernet"
  weight_decay: 0.1
  k_plus: 1
  exponent: -0.25
  lrelu_slope: 0
#  weight_penalty: exp
  zero_order: True
  num_runs: 10  # original split
